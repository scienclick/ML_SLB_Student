{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-fund-d21",
      "display_name": "Python (env Fund-d21)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creator": "ashamsa@slb.com",
    "createdOn": 1663178326797,
    "tags": [],
    "customFields": {},
    "modifiedBy": "dbecerra6@slb.com",
    "versionNumber": 1
  },
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kernel: `Fund-d21`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Day 2 - Tutorial 1\n\nIn this tutorial, we will learn how to import and manipulate well log data for reservoir evaluation. The tutorial is subdivided into four sections:\n\n1. Exploring Well log data (LAS file)\n2. Importing well tops \n3. Defining facies using well logs\n4. Plotting well log data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Well Log Data \n\nLog ASCII Standard (LAS) files are the most common oil \u0026 gas industry format used for storing well log data.\n\nIn this portion of the tutorial we are going to import a .las file to explore and manipulate its content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Install Required Packages"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# !pip install lasio\n# !pip install plotly\n\n# If the libraries are already installed in the current environment, the output message will be \"Requirement already satisfied\""
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Import Libraries"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "source": [
        "# Import required libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport lasio"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Step 3: Import the .las file \n\nUse the Lasio library to import the .LAS file -\u003e \"Diamond-14.las\"\n"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "source": [
        "# Read the .LAS file\n\nimport dataiku, os\n\nfolder_path \u003d dataiku.Folder(\u0027data\u0027).get_path()\nfile_path_D14 \u003d os.path.join(folder_path, \"Diamond-14.las\")\n\nD14 \u003d lasio.read(file_path_D14)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Step 4: Display the Data in the .LAS file\n\nNow that our file has been loaded, we can display its content: Header, curves description, and log data "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false
      },
      "source": [
        "# Display the header of the .LAS file\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Display the description of the log curves present in the .LAS file\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Display a summary of the log data in the .LAS file\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Step 5: Create a Dataframe \n\nIn this step we will convert the data loaded using lasio (\u0027D14\u0027) to a pandas dataframe. This step will facilitate the data manipulation and further plotting"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Create the dataframe using the \"D14\" dataset, call it D14_logs\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Print a summary of the newly created dataframe\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false
      },
      "source": [
        "# Display the first few rows of the dataframe\n\n\n\n# The number inside the brackes refers to the amount of rows to be displayed"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Generate descriptive statistics of the log data\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We can also use the .T() function to transpose the data frame (index and columns)\n\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Replace Negative Values by NaN\n\nFrom the step above we can see that some logs (RHOB, DT, etc) contain negative numbers. Such values are most likely associated with tool errors and therefore should be replaced \n"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Replace negative values on the \u0027RHOB\u0027 and \u0027DT\u0027 logs using the .mask () function\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check the statistics for the well logs that we replaced the negative values for\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Compute a New Well Log \n\nAfter cleaning our log data from negative values, we can now use it to estimate geological properties. As an example, we will calculate an Acoustic Impedance (AI) log using the density (RHOB) and sonic logs (DT)\n\nAI\u003d Bulk density x Velocity\n\nNote that the sonic log measures transit time, so we will need to compute velocity\n\nVelocity\u003d 1000000 / DT "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Calculate acoustic impedance (AI): AI\u003d density x velocity\n\nD14_logs[\u0027AI\u0027] \u003d D14_logs[\u0027RHOB\u0027] * 1000000 / D14_logs[\"DT\"]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Validate the resulting AI log by looking at its stats\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Replace Infinity Values\n\nNote that the min and max values of the AI log are -inf and inf. \n\nIn this case, the infitine (inf) values potencially come when 0 is in the denominator (DT \u003d 0)\n\nWe can use the .mask () function to replace inf values by NaN"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Replace the inf and -inf data in the AI log by NaN\n\nD14_logs.AI \u003d D14_logs.AI.mask((D14_logs.AI \u003d\u003d np.inf) | (D14_logs.AI \u003d\u003d -np.inf), np.NaN)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Validate the results by looking at the stats of the AI log again\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Identify and Handle Outliers\n\nWe will create a box plot to detect potential outliers in the data. We will use the AI log as an example"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false
      },
      "source": [
        "# Evaluate the range of the data from a boxplot and identify potential outliers in the AI\n\nD14_logs[[\"AI\"]].plot(kind\u003d\"box\", title \u003d \"AI Log - Raw Data\")\n\nplt.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# First, let\u0027s print the number of rows in the AI column before dropping outliers\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Remove the rows for AI\u003e25000 (Feel free to play with this number)\n\nD14_logs \u003d D14_logs[D14_logs.AI \u003c 25000]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Print the number of rows after dropping the outliers\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display the content of the edited AI column\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Create a boxplot of the AI data after dropping the outliers\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Create a histogram of the AI log to validate the data range after dropping outliers \n\nD14_logs.AI.plot(kind\u003d\"hist\", title \u003d \"Acoustic Impedance Log\")\nplt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Step 10: Create a Sub-set of Data\n\nTo facilitate the visualization and manipulation of the log data, we can create a sub-data frame to keep only the well logs that are required for the rest of the tutorial\n\nAmong the 38 columns in the original .LAS files (+ AI log), we will make a sub-set containing the following curves: CALI, GR, DT, RHOB, NPHI, PHIT, RT, VCL, and AI\n"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false
      },
      "source": [
        "# Create a sub-set selecting the following columns: \u0027CALI\u0027, \u0027GR\u0027,\u0027DT\u0027,\u0027RHOB\u0027,\u0027NPHI\u0027,\u0027PHIT\u0027,\u0027RT\u0027,\u0027VCL\u0027,\u0027AI\u0027\n\n\n\n# Double brackets return a dataframe"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "source": [
        "# Print a summary of the resulting sub-set\n\nD14_final.head(10)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Import Well Tops \n\nImport well tops to use them as depth filters to limit the calculations to the zone of interest \n\n- Import Well Tops \n- Define area of Interest between two well tops "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Load Well Tops Data From a .csv File"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Read well tops from a .csv file. Note that the .csv file was previously imported into Dataiku\n\ntop_file_path \u003d os.path.join(folder_path, \u0027Tops.csv\u0027)\nmydataset \u003d dataiku.Dataset(\"Tops\")\ntops \u003d mydataset.get_dataframe()\n\n# Display the content of the loaded well tops file\n\ntops"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Run Basic Operations on the Well Tops"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "source": [
        "# Compute the average depth for each formation top for the three wells (Diamond-14, DIamond-10 and Diamond-03)\n\ntops.groupby(\"Surface\").mean()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Step 3: Re-Arrange the well tops dataframe  "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Re-arrange the dataframe using the .pivot_table () function for: columns\u003d Surface and index\u003d Well name\n\ntops.pivot_table(columns\u003d\"Surface\", index\u003d\"Well name\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Step 4: Sort Well Tops"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Sort the tops in each well based on depth (\u0027MD\u0027)\n\ntops.groupby(\"Well name\").apply(lambda df_: df_.sort_values(by\u003d\"MD\"))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Step 5: Create a Sub-Set of Well Logs Over a Specific Zone\n\nNow, we will create a sub-set of our log dataframe to keep only the values within the interval of \"HOUSTON\" and \"HOUSTON_BASE\" well tops\n"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Index the \u0027tops\u0027 dataframe based on well (\"Well name\") and well top (\"Surface\")\n\ntops.set_index([\"Well name\", \"Surface\"], inplace\u003dTrue)\n\n# Display the resulting dataframe\n\n\n\n#As shown in the output table, the data now has 2 index columns, Well name and Surface"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Define two variables to store the top\u003d HOUSTON and base\u003d HOUSTON_BASE of our zone of interest\n\ntop \u003d tops.loc[(\"Diamond-14\", \"HOUSTON\"), \"MD\"]\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use the .loc() fuction to retrieve the data values in the zone of interest (within \u0027top\u0027 and \u0027base\u0027)\n\nD14_ZOI\u003dD14_final.loc[(D14_final.index \u003e top) \u0026 (D14_final.index \u003c base)]\n\n# Display the resulting dataframe\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Facies Classification Using Well Logs\n\nIn this portion of the tutorial we will create a facies classification based on a Gamma Ray cut off"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Create a function to define the facies classes -\u003e GR\u003e 50 Shale, GR\u003c50 Sand\n\ndef GR_Facies(x):\n    if x \u003c 50:\n        return \"Sand\"\n    else:\n        return \"Shale\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Create a column named \u0027Facies Type\u0027 and apply the \u0027GR_Facies\u0027 function to it\n\nD14_ZOI[\"Facies Type\"] \u003d D14_ZOI[\u0027GR\u0027].apply(GR_Facies)\n\n\n# Display a summary of the dataset. It should include the \u0027Facies Type\u0027 column\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Plotting Well Log Data\n\nThe analysis of well log data relies on a variety of plots (line plots with data vs depth), histograms, crossplots, etc.\n\nIn this exercise we will explore the usage of various python libraries including matplotlib, seaborn and plotly, to create the most frequently used plots for well log evaluation:\n\n- Line plot\n- 2D and 3D scatter plot\n- Box plots\n- Histogram \n- Correlation matrix"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false
      },
      "source": [
        "# Using Matplotlib create a vertical plot of the GR log within the ZOI\n\nplt.plot(D14_ZOI[\u0027GR\u0027],D14_ZOI.index)\n\nplt.show()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# We can improve the plot above by adjusting the size, adding a title, axis labels and a grid\n\nplt.figure(figsize\u003d(2, 8))\n\nplt.title(\"GR D14 Well\")\n\nplt.ylabel(\"Depth\")\n\nplt.xlabel(\"GR\")\n\nplt.grid(True)\n\nplt.plot(D14_ZOI[\"GR\"],D14_ZOI.index, color\u003d\u0027brown\u0027, marker\u003d\u0027.\u0027)\nplt.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use Matplotlib to create a scatter plot of Gamma Ray Vs Bulk Density, with markers colored by Transit Time\n\nD14_final.plot(x\u003d\"GR\", y\u003d\"RHOB\", kind\u003d\"scatter\",\n               figsize\u003d(8,8),\n               c\u003d\"DT\",cmap\u003d\"plasma\", \n               vmin\u003d90,vmax\u003d150,\n               xlim\u003d(10,110),ylim\u003d(1.8,2.5), sharex\u003dFalse)\n\nplt.show()\n\n# sharex\u003dFalse is added to force the display of the xlabel, you can try removing it from the .plot() fuction"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use plotly to create a 3D plot or Neutron porosity, Bulk density and Gamma Ray with markers colored by DT\n\nD_Scatt \u003d px.scatter_3d(data_frame\u003dD14_ZOI, \n                        x\u003d\u0027NPHI\u0027, \n                        y\u003d\u0027RHOB\u0027,\n                        z\u003d\u0027GR\u0027, \n                        color\u003d\u0027DT\u0027)\n\nD_Scatt.show()\n\n# Make sure to explore the icons on the top right of the plot!"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use plotly to create a histogram of the Bulk density log. Customize the bin number (\u0027nbins\u0027)! \n\nhist1 \u003d px.histogram(data_frame\u003dD14_ZOI, \n                     x\u003d[\u0027RHOB\u0027], nbins\u003d20,\n                     width\u003d 600, height\u003d600,\n                     title\u003d\u0027Bulk Density distribution within the Houston ZOI\u0027)\n\nhist1.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We can also can create a histogram of the bulk density grouped/colored by facies\n\nfig \u003d px.histogram(data_frame\u003dD14_ZOI,\n                   x\u003d\u0027RHOB\u0027, nbins\u003d20,\n                   color\u003d\"Facies Type\",\n                   width\u003d 500, height\u003d500,\n                   title\u003d\u0027Bulk Density by Facies\u0027)\n\nfig.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use plotly to create a boxplot of the distribution of the gamma ray by facies\n\nbox_plot \u003d px.box(data_frame\u003dD14_ZOI,\n                  x\u003d\u0027Facies Type\u0027, y\u003d\u0027GR\u0027,\n                  color\u003d\u0027Facies Type\u0027,\n                  width\u003d 500, height\u003d500,\n                  title\u003d\u0027Gamma Ray by Facies\u0027)\n\nbox_plot.show()\n\n# Make sure to hover over the boxplot to read the statistics!"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use plotly to create a strip plot of the Neutron porosity, grouped by facies\n\nfig \u003d px.strip(data_frame\u003dD14_ZOI,\n               y\u003d\u0027NPHI\u0027, x\u003d \u0027Facies Type\u0027,\n               color\u003d\"Facies Type\",\n               width\u003d 500, height\u003d500,\n               title\u003d\u0027Distribution of Neutron Porosity log by facies\u0027)\nfig.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use Plotly to create a scatterplot of Bulk density versus Neutron Porosity and compute a trend line for the data\n\nfig \u003d px.scatter(data_frame\u003d D14_ZOI,\n                 x\u003d\u0027NPHI\u0027,y\u003d\"RHOB\",\n                 color\u003d\"Facies Type\",\n                 trendline\u003d\u0027ols\u0027,\n                 width \u003d 500, height\u003d500,\n                 title\u003d\u0027Bulk Density versus Neutron Porosity by facies\u0027)\nfig.show()\n\n# OLS stands for Ordinary Least Squares (OLS) regression"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Calculate and Visualize a Correlation Matrix "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use the function .corr() to compute the pearson correlation coefficient for all columns within the D14.ZOI dataframe\n\nMatrix_Full\u003d D14_ZOI.corr(method \u003d\u0027pearson\u0027).round(2)\n\nMatrix_Full"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Now let\u0027s select a subset of well logs to facilitate the visualization of the correlation matrix\n\nMatrix_Small \u003d D14_ZOI[[\u0027DT\u0027, \u0027GR\u0027, \u0027RHOB\u0027, \u0027NPHI\u0027]].corr().round(2)\n\nMatrix_Small"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Use seaborn to create a heat map of the correlation matrix (\u0027Matrix_Small\u0027)\n\nsns.heatmap(Matrix_Small, \n            annot\u003dTrue, \n            vmax\u003d1, \n            vmin\u003d-1, \n            center\u003d0,\n            cmap\u003d\u0027vlag\u0027)\nplt.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# We can use Plotly to create a scatterplot matrix to display the graphical correlation between some logs [\u0027RHOB\u0027,\u0027NPHI\u0027,\u0027DT\u0027,\u0027GR\u0027]\n\nfig \u003d px.scatter_matrix(data_frame\u003d D14_ZOI, \n                        dimensions\u003d [\u0027RHOB\u0027,\u0027NPHI\u0027,\u0027DT\u0027,\u0027GR\u0027], \n                        title\u003d \u0027Correlation of Bulk Density, Neutron Porosity, Sonic and Gamma Ray logs by facies\u0027,\n                        color\u003d \"Facies Type\",\n                        width\u003d 700,height\u003d 650)\nfig.show()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# We can also use plotly to create a parallel Coordinates plot to visualize the correlation between some logs [\u0027RHOB\u0027,\u0027NPHI\u0027,\u0027DT\u0027,\u0027GR\u0027]\n\nfig \u003d px.parallel_coordinates(data_frame\u003dD14_ZOI, \n                              dimensions\u003d[\u0027RHOB\u0027,\"NPHI\",\"DT\",\"GR\"],\n                              color\u003d\"GR\")\nfig.show()\n\n# Each line represents a row in the data frame!"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}